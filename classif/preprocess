import xml.etree.ElementTree as ET_std
import lxml.etree as ET_lxml
import re
from collections import Counter
import unicodedata
import numpy as np
import matplotlib.pyplot as plt

def load_and_preprocess_xml(xml_file_path, min_class_samples=5):
    records = []
    parser = ET_lxml.XMLParser(recover=True, encoding='utf-8')
    tree = ET_lxml.parse(xml_file_path, parser)
    root = tree.getroot()

    for record in root.iter('record'):
        rec_id_elem = record.find('id')
        service_elem = record.find('service')
        topic_elem = record.find('topic')
        description_elem = record.find('description')
        attachments_elem = record.find('attachments')

        rec_id = rec_id_elem.text if rec_id_elem is not None and rec_id_elem.text is not None else ""
        service = service_elem.text if service_elem is not None and service_elem.text is not None else ""
        topic = topic_elem.text if topic_elem is not None and topic_elem.text is not None else ""
        description = description_elem.text if description_elem is not None and description_elem.text is not None else ""
        attachments = attachments_elem.text if attachments_elem is not None and attachments_elem.text is not None else ""

        combined_text = f"{topic} {description}".strip()
        records.append({
            'id': rec_id,
            'service': service,
            'raw_text': combined_text,
            'attachments': attachments
        })

    service_counts = Counter([r['service'] for r in records])
    valid_services = {service for service, count in service_counts.items() if count >= min_class_samples}
    filtered_records = [r for r in records if r['service'] in valid_services]

    processed_records = []
    for record in filtered_records:
        processed_text = preprocess_text(record['raw_text'])
        if processed_text:
            processed_records.append({
                'id': record['id'],
                'service': record['service'],
                'combined_text': processed_text,
                'attachments': record['attachments']
            })

    return processed_records

def preprocess_text(text):
    if not text:
        return ""
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'[^а-яёА-ЯЁa-zA-Z0-9\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'(?<=[а-яёa-z0-9])(?=[А-ЯЁA-Z])|(?<=[А-ЯЁA-Z])(?=[А-ЯЁA-Z][а-яёa-z])', ' ', text)
    text = text.strip()
    return text

if __name__ == "__main__":
    XML_PATH = "path/to/your/dataset.xml"
    MIN_SAMPLES = 10

    print("Loading and preprocessing data...")
    processed_data = load_and_preprocess_xml(XML_PATH, min_class_samples=MIN_SAMPLES)

    print(f"Loaded {len(processed_data)} records after filtering and preprocessing.")
    if processed_data:
        print("Sample processed record:")
        print(processed_data[0])

        print("\n--- Dataset Statistics ---")
        num_classes = len(set(r['service'] for r in processed_data))
        print(f"Number of unique classes (after filtering): {num_classes}")

        service_counts_after_filter = Counter([r['service'] for r in processed_data])
        counts = list(service_counts_after_filter.values())

        print(f"Min samples per class: {min(counts)}")
        print(f"Max samples per class: {max(counts)}")
        print(f"Mean samples per class: {np.mean(counts):.2f}")
        print(f"Median samples per class: {np.median(counts):.2f}")

        text_lengths = [len(r['combined_text']) for r in processed_data]
        print(f"Min text length: {min(text_lengths)}")
        print(f"Max text length: {max(text_lengths)}")
        print(f"Mean text length: {np.mean(text_lengths):.2f}")

        plt.figure(figsize=(12, 6))
        plt.bar(range(len(service_counts_after_filter)), list(service_counts_after_filter.values()))
        plt.title('Distribution of samples per class (after filtering)')
        plt.xlabel('Class (service)')
        plt.ylabel('Number of samples')
        plt.xticks(rotation=90)
        plt.tight_layout()
        plt.show()

        plt.figure(figsize=(10, 6))
        plt.hist(text_lengths, bins=50, edgecolor='black')
        plt.title('Distribution of text lengths (combined_text)')
        plt.xlabel('Text length (characters)')
        plt.ylabel('Number of samples')
        plt.show()
